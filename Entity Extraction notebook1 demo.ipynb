{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5589ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cec4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14abeb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.31.0\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: C:\\Users\\AKSHAT RAI LADDHA\\anaconda3\\Lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1158f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90fa9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[ C L S ]', '[ P A D ]'), ('J o h n', '[ P A D ]'), ('w o r k s', '[ P A D ]'), ('a t', '[ P A D ]'), ('M i c r o s o f t', '[ P A D ]'), ('C o r p', '[ P A D ]'), ('a s', '[ P A D ]'), ('a', '[ P A D ]'), ('s o f t w a r e', '[ P A D ]'), ('e n g i n e e r', '[ P A D ]'), ('i n', '[ P A D ]'), ('N e w', '[ P A D ]'), ('Y o r k', '[ P A D ]'), ('C i t y', '[ P A D ]'), ('.', '[ P A D ]'), ('[ S E P ]', '[ P A D ]')]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Sample text for NER\n",
    "text = \"John works at Microsoft Corp as a software engineer in New York City.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "\n",
    "# Get the predicted label ids\n",
    "predicted_label_ids = torch.argmax(outputs.logits, dim=2).squeeze()\n",
    "\n",
    "# Convert label ids back to entity labels\n",
    "labels = [tokenizer.decode(label_id) for label_id in predicted_label_ids]\n",
    "\n",
    "# Post-process to extract entities\n",
    "entities = []\n",
    "current_entity = \"\"\n",
    "for token, label in zip(tokens['input_ids'][0], labels):\n",
    "    token_str = tokenizer.decode(token)\n",
    "    if \"##\" in token_str:  # Handling subwords\n",
    "        current_entity += token_str.replace(\"##\", \"\")\n",
    "    else:\n",
    "        if current_entity:\n",
    "            entities.append((current_entity, label))\n",
    "            current_entity = \"\"\n",
    "        if label != 'O':  # 'O' represents no entity\n",
    "            entities.append((token_str, label))\n",
    "\n",
    "# Print the extracted entities\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed6fa5",
   "metadata": {},
   "source": [
    "### Model 1 :BERT NER model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f47a3153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: A | Type: I-PER\n",
      "Entity: ##ks | Type: I-PER\n",
      "Entity: ##hat | Type: I-PER\n",
      "Entity: Care | Type: I-ORG\n",
      "Entity: ##lon | Type: I-ORG\n",
      "Entity: Global | Type: I-ORG\n",
      "Entity: Solutions | Type: I-ORG\n",
      "Entity: Bangalore | Type: I-LOC\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\") #using ner trained model by hugging face to extract entites \n",
    "\n",
    "# Example text\n",
    "text = \"Myself Akshat, worked as ML intern in Carelon Global Solutions from May to June in Bangalore\"\n",
    "\n",
    "# Perform Named Entity Recognition on the text\n",
    "entities = ner_pipeline(text)\n",
    "\n",
    "# Print the recognized entities\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']} | Type: {entity['entity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4b859",
   "metadata": {},
   "source": [
    "Extracted entities with particular information using NER model from hugging face. Generation of subwords from words such as Akshat to A, ##ks, ##hat this is because the model's tokenizer is based on WordPiece tokenization, where words are split into subword units to handle out-of-vocabulary (OOV) words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04177b16",
   "metadata": {},
   "source": [
    "### trying out luck with other fine tuned models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a2ab5",
   "metadata": {},
   "source": [
    "### Model 2: Fine tuned model by Balamurugan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12397d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Loading the pipeline from hub\n",
    "# Pipeline handles the preprocessing and post processing steps\n",
    "model_checkpoint = \"balamurugan1603/bert-finetuned-ner\"\n",
    "namedEntityRecogniser = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f2f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Myself Akshat Rai Laddha, working as Machine Learning intern at Carelon global Solution in Bangalore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e2182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output = namedEntityRecogniser([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bcc9f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'PER', 'score': 0.9970353, 'word': 'Akshat Rai Laddha', 'start': 7, 'end': 24}, {'entity_group': 'ORG', 'score': 0.82005215, 'word': 'Machine Learning', 'start': 37, 'end': 53}, {'entity_group': 'ORG', 'score': 0.96633375, 'word': 'Carelon', 'start': 64, 'end': 71}, {'entity_group': 'ORG', 'score': 0.84763527, 'word': 'Solution', 'start': 79, 'end': 87}, {'entity_group': 'LOC', 'score': 0.995404, 'word': 'Bangalore', 'start': 91, 'end': 100}]]\n"
     ]
    }
   ],
   "source": [
    "print(sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40965c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "327f7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(pipeline_output, texts):\n",
    "    \n",
    "    \"\"\" Visualizes text and their Named entities.\n",
    "    \n",
    "    Args:\n",
    "        pipeline_output (list): Output of the pipeline.\n",
    "        texts (list): List containing original text.\n",
    "    \n",
    "    Returns:\n",
    "        Nothing\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(sample_output)):\n",
    "        entities = []\n",
    "        for ents in sample_output[i]:\n",
    "            entities.append({\"end\": ents[\"end\"], \"label\": ents[\"entity_group\"], \"start\": ents[\"start\"]})\n",
    "        displacy.render({\n",
    "            \"ents\": entities,\n",
    "            \"text\": texts[i]\n",
    "        }, style=\"ent\", manual=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d53acfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Myself \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Akshat Rai Laddha\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", working as \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ML\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " intern at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Carelon global Solution\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bangalore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# results visualization\n",
    "visualize(sample_output, [text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ec7d0",
   "metadata": {},
   "source": [
    "## # Model 3: Fine tuned Model by Rashid (additional tags : building, art, misc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a060b8",
   "metadata": {},
   "source": [
    "Model details: Deberta-v3-base and finetuned it on Few-NERD, NER based dataset with 180k+ examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "159570f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Loading the pipeline from hub\n",
    "# Pipeline handles the preprocessing and post processing steps\n",
    "model_checkpoint = \"RashidNLP/NER-Deberta\"\n",
    "namedEntityRecogniser = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "16894c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Myself Akshat Rai Laddha, working as ML intern at Carelon global Solution's Bagmane infotech park in Hyderabad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b5937f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "sample_output = namedEntityRecogniser([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "25025d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'person', 'score': 0.98134595, 'word': 'Akshat Rai Laddha', 'start': 6, 'end': 24}, {'entity_group': 'organization', 'score': 0.72849536, 'word': \"Carelon global Solution's\", 'start': 49, 'end': 75}, {'entity_group': 'location', 'score': 0.50732577, 'word': 'Bagmane', 'start': 75, 'end': 83}, {'entity_group': 'organization', 'score': 0.4707223, 'word': 'infotech park', 'start': 83, 'end': 97}]]\n"
     ]
    }
   ],
   "source": [
    "print(sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "666bc962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d0b996b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(pipeline_output, texts):\n",
    "    \n",
    "    \"\"\" Visualizes text and their Named entities.\n",
    "    \n",
    "    Args:\n",
    "        pipeline_output (list): Output of the pipeline.\n",
    "        texts (list): List containing original text.\n",
    "    \n",
    "    Returns:\n",
    "        Nothing\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(sample_output)):\n",
    "        entities = []\n",
    "        for ents in sample_output[i]:\n",
    "            entities.append({\"end\": ents[\"end\"], \"label\": ents[\"entity_group\"], \"start\": ents[\"start\"]})\n",
    "        displacy.render({\n",
    "            \"ents\": entities,\n",
    "            \"text\": texts[i]\n",
    "        }, style=\"ent\", manual=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "24b462dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Myself\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Akshat Rai Laddha\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">person</span>\n",
       "</mark>\n",
       ", working as ML intern at\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Carelon global Solution's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">organization</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     Bagmane\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">location</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "     infotech park\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">organization</span>\n",
       "</mark>\n",
       " in Hyderabad</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(sample_output, [text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fac005e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'person', 'score': 0.98134595, 'word': 'Akshat Rai Laddha', 'start': 6, 'end': 24}, {'entity_group': 'organization', 'score': 0.72849536, 'word': \"Carelon global Solution's\", 'start': 49, 'end': 75}, {'entity_group': 'location', 'score': 0.50732577, 'word': 'Bagmane', 'start': 75, 'end': 83}, {'entity_group': 'organization', 'score': 0.4707223, 'word': 'infotech park', 'start': 83, 'end': 97}]]\n"
     ]
    }
   ],
   "source": [
    "print(sample_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bf8ab",
   "metadata": {},
   "source": [
    "feedback: not capturing hyderabad as our output location label, rejecting this fine tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea715131",
   "metadata": {},
   "source": [
    "### Model Stacking concept or pipelineing models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7e1a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# Loading the pipeline from hub\n",
    "# Pipeline handles the preprocessing and post processing steps\n",
    "model_checkpoint = \"algiraldohe/lm-ner-linkedin-skills-recognition\"\n",
    "namedEntityRecogniser_m2 = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b7d10e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Myself Akshat Rai Laddha, working as Machine Learning engineer at Carelon Global Solutions in Bangalore. Proficient in public speaking and coding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d920f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_results = namedEntityRecogniser_m2([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2269650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'TECHNICAL', 'score': 0.99462366, 'word': 'machine learning', 'start': 37, 'end': 53}, {'entity_group': 'SOFT', 'score': 0.7944664, 'word': 'public speaking', 'start': 119, 'end': 134}]]\n"
     ]
    }
   ],
   "source": [
    "print(m2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa2fb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pipeline from hub\n",
    "# Pipeline handles the preprocessing and post processing steps\n",
    "model_checkpoint = \"balamurugan1603/bert-finetuned-ner\"\n",
    "namedEntityRecogniser_m1 = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d801def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_results = namedEntityRecogniser_m1([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52edc8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'PER', 'score': 0.99715745, 'word': 'Akshat Rai Laddha', 'start': 7, 'end': 24}, {'entity_group': 'ORG', 'score': 0.99314034, 'word': 'Carelon Global Solutions', 'start': 66, 'end': 90}, {'entity_group': 'LOC', 'score': 0.9948565, 'word': 'Bangalore', 'start': 94, 'end': 103}]]\n"
     ]
    }
   ],
   "source": [
    "print(m1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "72a364fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_results.extend(m2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aec14a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'PER', 'score': 0.99715745, 'word': 'Akshat Rai Laddha', 'start': 7, 'end': 24}, {'entity_group': 'ORG', 'score': 0.99314034, 'word': 'Carelon Global Solutions', 'start': 66, 'end': 90}, {'entity_group': 'LOC', 'score': 0.9948565, 'word': 'Bangalore', 'start': 94, 'end': 103}], [{'entity_group': 'TECHNICAL', 'score': 0.99462366, 'word': 'machine learning', 'start': 37, 'end': 53}, {'entity_group': 'SOFT', 'score': 0.7944664, 'word': 'public speaking', 'start': 119, 'end': 134}]]\n"
     ]
    }
   ],
   "source": [
    "print(m1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47ace7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data=m1_results[0]\n",
    "merged_data.extend(m1_results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ce36ee17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.99715745, 'word': 'Akshat Rai Laddha', 'start': 7, 'end': 24}, {'entity_group': 'ORG', 'score': 0.99314034, 'word': 'Carelon Global Solutions', 'start': 66, 'end': 90}, {'entity_group': 'LOC', 'score': 0.9948565, 'word': 'Bangalore', 'start': 94, 'end': 103}, {'entity_group': 'TECHNICAL', 'score': 0.99462366, 'word': 'machine learning', 'start': 37, 'end': 53}, {'entity_group': 'SOFT', 'score': 0.7944664, 'word': 'public speaking', 'start': 119, 'end': 134}]\n"
     ]
    }
   ],
   "source": [
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55ffc9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_group': 'PER', 'score': 0.99715745, 'word': 'Akshat Rai Laddha', 'start': 7, 'end': 24}\n",
      "{'entity_group': 'TECHNICAL', 'score': 0.99462366, 'word': 'machine learning', 'start': 37, 'end': 53}\n",
      "{'entity_group': 'ORG', 'score': 0.99314034, 'word': 'Carelon Global Solutions', 'start': 66, 'end': 90}\n",
      "{'entity_group': 'LOC', 'score': 0.9948565, 'word': 'Bangalore', 'start': 94, 'end': 103}\n",
      "{'entity_group': 'SOFT', 'score': 0.7944664, 'word': 'public speaking', 'start': 119, 'end': 134}\n"
     ]
    }
   ],
   "source": [
    "# Sort the list based on 'start' index in ascending order\n",
    "sorted_data = sorted(merged_data, key=lambda x: x['start'])\n",
    "\n",
    "# Print the sorted entities\n",
    "for entity in sorted_data:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa27da48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.99715745, 'word': 'Akshat Rai Laddha', 'start': 7, 'end': 24}, {'entity_group': 'TECHNICAL', 'score': 0.99462366, 'word': 'machine learning', 'start': 37, 'end': 53}, {'entity_group': 'ORG', 'score': 0.99314034, 'word': 'Carelon Global Solutions', 'start': 66, 'end': 90}, {'entity_group': 'LOC', 'score': 0.9948565, 'word': 'Bangalore', 'start': 94, 'end': 103}, {'entity_group': 'SOFT', 'score': 0.7944664, 'word': 'public speaking', 'start': 119, 'end': 134}]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5823c07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Myself Akshat Rai Laddha, working as Machine Learning engineer at Carelon Global Solutions in Bangalore. Proficient in public speaking and coding'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aad81ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(pipeline_output, texts):\n",
    "    \n",
    "    \"\"\" Visualizes text and their Named entities.\n",
    "    \n",
    "    Args:\n",
    "        pipeline_output (list): Output of the pipeline.\n",
    "        texts (list): List containing original text.\n",
    "    \n",
    "    Returns:\n",
    "        Nothing\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(final_list)):\n",
    "        entities = []\n",
    "        for ents in final_list[i]:\n",
    "            entities.append({\"end\": ents[\"end\"], \"label\": ents[\"entity_group\"], \"start\": ents[\"start\"]})\n",
    "        displacy.render({\n",
    "            \"ents\": entities,\n",
    "            \"text\": texts[i]\n",
    "        }, style=\"ent\", manual=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0f19eec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Myself \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Akshat Rai Laddha\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", working as \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Machine Learning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECHNICAL</span>\n",
       "</mark>\n",
       " engineer at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Carelon Global Solutions\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bangalore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". Proficient in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    public speaking\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SOFT</span>\n",
       "</mark>\n",
       " and coding</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m visualize(sorted_data, [text])\n",
      "Cell \u001b[1;32mIn[88], line 20\u001b[0m, in \u001b[0;36mvisualize\u001b[1;34m(pipeline_output, texts)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ents \u001b[38;5;129;01min\u001b[39;00m final_list[i]:\n\u001b[0;32m     17\u001b[0m     entities\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m: ents[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: ents[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity_group\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m: ents[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[0;32m     18\u001b[0m displacy\u001b[38;5;241m.\u001b[39mrender({\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ments\u001b[39m\u001b[38;5;124m\"\u001b[39m: entities,\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: texts[i]\n\u001b[0;32m     21\u001b[0m }, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m\"\u001b[39m, manual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "visualize(sorted_data, [text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0555973f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Myself \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Akshat Rai Laddha\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", working as \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Machine Learning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECHNICAL</span>\n",
       "</mark>\n",
       " engineer at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Carelon Global Solutions\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bangalore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". Proficient in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    public speaking\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SOFT</span>\n",
       "</mark>\n",
       " and coding</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 29\u001b[0m\n\u001b[0;32m     22\u001b[0m         displacy\u001b[38;5;241m.\u001b[39mrender({\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[0;32m     24\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ments\u001b[39m\u001b[38;5;124m\"\u001b[39m: entities_to_render,\n\u001b[0;32m     25\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNamed Entities\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m         }, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m\"\u001b[39m, manual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Call the visualize function\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m visualize(sorted_data,[text])\n",
      "Cell \u001b[1;32mIn[88], line 20\u001b[0m, in \u001b[0;36mvisualize\u001b[1;34m(pipeline_output, texts)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ents \u001b[38;5;129;01min\u001b[39;00m final_list[i]:\n\u001b[0;32m     17\u001b[0m     entities\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m: ents[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: ents[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity_group\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m: ents[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[0;32m     18\u001b[0m displacy\u001b[38;5;241m.\u001b[39mrender({\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ments\u001b[39m\u001b[38;5;124m\"\u001b[39m: entities,\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: texts[i]\n\u001b[0;32m     21\u001b[0m }, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m\"\u001b[39m, manual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def visualize_modified(pipeline_output, texts):\n",
    "    \"\"\"\n",
    "    Visualizes text and their Named entities.\n",
    "\n",
    "    Args:\n",
    "        pipeline_output (list): Output of the pipeline.\n",
    "        texts (list): List containing original text.\n",
    "\n",
    "    Returns:\n",
    "        Nothing\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for entities, text in zip(pipeline_output, texts):\n",
    "        entities_to_render = []\n",
    "        for entity in entities:\n",
    "            entities_to_render.append({\n",
    "                \"start\": entity[\"start\"],\n",
    "                \"end\": entity[\"end\"],\n",
    "                \"label\": entity[\"entity_group\"]\n",
    "            })\n",
    "        displacy.render({\n",
    "            \"text\": text,\n",
    "            \"ents\": entities_to_render,\n",
    "            \"title\": \"Named Entities\"\n",
    "        }, style=\"ent\", manual=True)\n",
    "\n",
    "# Call the visualize function\n",
    "visualize(sorted_data,[text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b5d0ef99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_group': 'PER', 'score': 0.99715745, 'word': 'Akshat Rai Laddha', 'start': 7, 'end': 24}\n",
      "{'entity_group': 'TECHNICAL', 'score': 0.99462366, 'word': 'machine learning', 'start': 37, 'end': 53}\n",
      "{'entity_group': 'ORG', 'score': 0.99314034, 'word': 'Carelon Global Solutions', 'start': 66, 'end': 90}\n",
      "{'entity_group': 'LOC', 'score': 0.9948565, 'word': 'Bangalore', 'start': 94, 'end': 103}\n",
      "{'entity_group': 'SOFT', 'score': 0.7944664, 'word': 'public speaking', 'start': 119, 'end': 134}\n"
     ]
    }
   ],
   "source": [
    "data = [[{'entity_group': 'PER', 'score': 0.99715745, 'word': 'Akshat Rai Laddha', 'start': 7, 'end': 24},\n",
    "         {'entity_group': 'ORG', 'score': 0.99314034, 'word': 'Carelon Global Solutions', 'start': 66, 'end': 90},\n",
    "         {'entity_group': 'LOC', 'score': 0.9948565, 'word': 'Bangalore', 'start': 94, 'end': 103}],\n",
    "        [{'entity_group': 'TECHNICAL', 'score': 0.99462366, 'word': 'machine learning', 'start': 37, 'end': 53},\n",
    "         {'entity_group': 'SOFT', 'score': 0.7944664, 'word': 'public speaking', 'start': 119, 'end': 134}]]\n",
    "\n",
    "# Merge the two lists into a single list\n",
    "merged_data = data[0]\n",
    "for entity in data[1]:\n",
    "    existing_entity = next((ent for ent in merged_data if ent['start'] == entity['start']), None)\n",
    "    if existing_entity is None or entity['score'] > existing_entity['score']:\n",
    "        merged_data.append(entity)\n",
    "\n",
    "# Sort the merged list based on 'start' index in ascending order\n",
    "sorted_data = sorted(merged_data, key=lambda x: x['start'])\n",
    "\n",
    "# Print the sorted and merged entities\n",
    "for entity in sorted_data:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f22ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
