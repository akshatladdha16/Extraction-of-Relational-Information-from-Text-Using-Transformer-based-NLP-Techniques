{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a62c72",
   "metadata": {},
   "source": [
    "### Method 1: Model stacking for entities extraction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b71b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously. “I can tell you very senior CEOs of major American car companies would shake my hand and turn away because I wasn’t worth talking to,” said Thrun, now the co-founder and CEO of online higher education startup Udacity, in an interview with Recode earlier this week. A little less than a decade later, dozens of self-driving startups have cropped up while automakers around the world clamor, wallet in hand, to secure their place in the fast-moving world of fully automated transportation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0978febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pipeline from hub\n",
    "from transformers import pipeline\n",
    "# Pipeline handles the preprocessing and post processing steps\n",
    "model_checkpoint_m1 = \"balamurugan1603/bert-finetuned-ner\"\n",
    "namedEntityRecogniser_m1 = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint_m1, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd6a927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'PER', 'score': 0.9975978, 'word': 'Sebastian Thrun', 'start': 5, 'end': 20}, {'entity_group': 'ORG', 'score': 0.98961675, 'word': 'Google', 'start': 61, 'end': 67}, {'entity_group': 'MISC', 'score': 0.9944423, 'word': 'American', 'start': 173, 'end': 181}, {'entity_group': 'PER', 'score': 0.9945845, 'word': 'Thrun', 'start': 271, 'end': 276}, {'entity_group': 'ORG', 'score': 0.97429544, 'word': 'Udacity', 'start': 340, 'end': 347}, {'entity_group': 'ORG', 'score': 0.9724045, 'word': 'Recode', 'start': 370, 'end': 376}]]\n"
     ]
    }
   ],
   "source": [
    "m1_results=namedEntityRecogniser_m1([text])\n",
    "print(m1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22649620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: for skill recognition\n",
    "model_checkpoint_m2 = \"algiraldohe/lm-ner-linkedin-skills-recognition\"\n",
    "namedEntityRecogniser_m2 = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint_m2, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53fd0ae",
   "metadata": {},
   "source": [
    "Labels in this model: ['B-BUS', 'B-SOFT', 'B-TECHNICAL', 'B-TECHNOLOGY', 'I-BUS', 'I-SOFT', 'I-TECHNICAL', 'I-TECHNOLOGY', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bff1d343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'BUS', 'score': 0.9896613, 'word': 'higher education', 'start': 315, 'end': 331}, {'entity_group': 'TECHNOLOGY', 'score': 0.9974293, 'word': 'less', 'start': 405, 'end': 409}, {'entity_group': 'BUS', 'score': 0.99113655, 'word': 'startups', 'start': 454, 'end': 462}]]\n"
     ]
    }
   ],
   "source": [
    "m2_results = namedEntityRecogniser_m2([text])\n",
    "print(m2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8663d",
   "metadata": {},
   "source": [
    "extracted results from both the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f9e889",
   "metadata": {},
   "source": [
    "##### Merging results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1832bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_results.extend(m2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96b798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two lists into a single list\n",
    "merged_results = m1_results[0]\n",
    "for entity in m1_results[1]:\n",
    "    existing_entity = next((ent for ent in merged_results if ent['start'] == entity['start']), None)\n",
    "    if existing_entity is None or entity['score'] > existing_entity['score']:\n",
    "        merged_results.append(entity)\n",
    "\n",
    "# Sort the merged list based on 'start' index in ascending order\n",
    "sorted_results= sorted(merged_results, key=lambda x: x['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a081ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.9975978, 'word': 'Sebastian Thrun', 'start': 5, 'end': 20}, {'entity_group': 'ORG', 'score': 0.98961675, 'word': 'Google', 'start': 61, 'end': 67}, {'entity_group': 'MISC', 'score': 0.9944423, 'word': 'American', 'start': 173, 'end': 181}, {'entity_group': 'PER', 'score': 0.9945845, 'word': 'Thrun', 'start': 271, 'end': 276}, {'entity_group': 'BUS', 'score': 0.9896613, 'word': 'higher education', 'start': 315, 'end': 331}, {'entity_group': 'ORG', 'score': 0.97429544, 'word': 'Udacity', 'start': 340, 'end': 347}, {'entity_group': 'ORG', 'score': 0.9724045, 'word': 'Recode', 'start': 370, 'end': 376}, {'entity_group': 'TECHNOLOGY', 'score': 0.9974293, 'word': 'less', 'start': 405, 'end': 409}, {'entity_group': 'BUS', 'score': 0.99113655, 'word': 'startups', 'start': 454, 'end': 462}]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c6db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result=[sorted_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf450e9",
   "metadata": {},
   "source": [
    "##### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9226b174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHAT RAI LADDHA\\anaconda3\\Lib\\site-packages\\cupy\\_environment.py:214: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AKSHAT RAI LADDHA\\anaconda3\\Lib\\site-packages\\cupy\\_environment.py:214: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AKSHAT RAI LADDHA\\anaconda3\\Lib\\site-packages\\cupy\\_environment.py:214: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f3f393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in 2007, few people outside of the company took him seriously. “I can tell you very senior CEOs of major \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " car companies would shake my hand and turn away because I wasn’t worth talking to,” said \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", now the co-founder and CEO of online \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    higher education\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BUS</span>\n",
       "</mark>\n",
       " startup \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Udacity\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", in an interview with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Recode\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " earlier this week. A little \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    less\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECHNOLOGY</span>\n",
       "</mark>\n",
       " than a decade later, dozens of self-driving \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    startups\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BUS</span>\n",
       "</mark>\n",
       " have cropped up while automakers around the world clamor, wallet in hand, to secure their place in the fast-moving world of fully automated transportation.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize(pipeline_output, texts):\n",
    "    for i in range(len(final_result)):\n",
    "        entities = []\n",
    "        for ents in final_result[i]:\n",
    "            entities.append({\"end\": ents[\"end\"], \"label\": ents[\"entity_group\"], \"start\": ents[\"start\"]})\n",
    "        displacy.render({\n",
    "            \"ents\": entities,\n",
    "            \"text\": texts[i]\n",
    "        }, style=\"ent\", manual=True)\n",
    "visualize(final_result,[text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003547e8",
   "metadata": {},
   "source": [
    "### Method 2: Using Spacy transformer based model to extract entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1de16105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy[cuda111,transformers] in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (3.3.0)\n",
      "Requirement already satisfied: cupy-cuda111<13.0.0,>=5.0.0b4 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (12.1.0)\n",
      "Requirement already satisfied: spacy-transformers<1.3.0,>=1.1.2 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy[cuda111,transformers]) (1.2.5)\n",
      "Requirement already satisfied: fastrlock>=0.5 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from cupy-cuda111<13.0.0,>=5.0.0b4->spacy[cuda111,transformers]) (0.8.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy[cuda111,transformers]) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda111,transformers]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda111,transformers]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda111,transformers]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda111,transformers]) (2023.5.7)\n",
      "Requirement already satisfied: transformers<4.31.0,>=3.4.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (4.30.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (2.0.1)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (0.9.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy[cuda111,transformers]) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy[cuda111,transformers]) (0.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy[cuda111,transformers]) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy[cuda111,transformers]) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from jinja2->spacy[cuda111,transformers]) (2.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from torch>=1.8.0->spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from torch>=1.8.0->spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from torch>=1.8.0->spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (2.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (0.16.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (0.3.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers<4.31.0,>=3.4.0->spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (2023.3.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\akshat rai laddha\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.0->spacy-transformers<1.3.0,>=1.1.2->spacy[cuda111,transformers]) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade spacy[cuda111,transformers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495bd08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously. “I can tell you very senior CEOs of major \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " car companies would shake my hand and turn away because I wasn’t worth talking to,” said \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", now the co-founder and CEO of online higher education startup \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Udacity\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", in an interview with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Recode\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    earlier this week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    A little less than a decade later\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dozens\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of self-driving startups have cropped up while automakers around the world clamor, wallet in hand, to secure their place in the fast-moving world of fully automated transportation.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp_trf = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "doc = nlp_trf(text)\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dff912",
   "metadata": {},
   "source": [
    "info about spacy englishh transformer based model: https://spacy.io/models/en#en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba8790",
   "metadata": {},
   "source": [
    "### Successfully extracted entities with different labels such as Person, Organization, Location, Skills , Miscellaneous etc. Finalized model: Spacy Model [en transformer] : less efforts but with model stacking concept we can use different model attributes based on the requirement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d573277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Sebastian Thrun | Label: PERSON\n",
      "Entity: Google | Label: ORG\n",
      "Entity: 2007 | Label: DATE\n",
      "Entity: American | Label: NORP\n",
      "Entity: Thrun | Label: PERSON\n",
      "Entity: Udacity | Label: ORG\n",
      "Entity: Recode | Label: ORG\n",
      "Entity: earlier this week | Label: DATE\n",
      "Entity: A little less than a decade later | Label: DATE\n",
      "Entity: dozens | Label: CARDINAL\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text} | Label: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc790fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART']\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_trf\") #transformer based model : model used is RoBERTa\n",
    "unique_labels = list(nlp.get_pipe(\"ner\").labels)\n",
    "\n",
    "# Print the unique labels\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e210b",
   "metadata": {},
   "source": [
    "The nlp.pipe() function efficiently processes the texts in batches and yields processed Doc objects one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9492df91",
   "metadata": {},
   "source": [
    "# Relationship Extraction Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377faa5",
   "metadata": {},
   "source": [
    "For explicit relationship, we can identify relational information between entities directly just by mapping it with each other but for implicit relationship we need to understand the grammatical formation btw entities . So using Spacy dependency parsing concept here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add02bf6",
   "metadata": {},
   "source": [
    "#### following this notebook : https://colab.research.google.com/drive/1lS3B7v_BHzRcynDEaPSz-aJ4wiA_n1Q-#scrollTo=CzWFRpeQX5z6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i.text, i.ent_iob_ + \"-\" + i.ent_type_) for i in doc]\n",
    "# to get info about all the tokens and labels assigned to it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041426ba",
   "metadata": {},
   "source": [
    "we will be using these tokens in dependecy parsing to understand contextual information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0ed24",
   "metadata": {},
   "source": [
    "once we've embedded our tokens, we want to encode them in a way incorporates their context in the sentence and their role in the downstream task. (E.g., \"security\" has a very different meaning if it's preceeded by \"national\" or \"social\"). BERT takes care of this part as it covers context of word birdirectionally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependency visualizer\n",
    "doc = nlp(text)\n",
    "sent = list(doc.sents)[4]\n",
    "displacy.render(sent, style=\"dep\")\n",
    "# so every element of list is one sentence that represents grammatical info of that sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = [(token.text, token.dep_, token.head.text) for token in doc]\n",
    "print(dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b8492",
   "metadata": {},
   "source": [
    "Labels available in the model: 'CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text with the SpaCy model\n",
    "doc = nlp_trf(text)\n",
    "\n",
    "# List to store the entities\n",
    "entities_list = []\n",
    "\n",
    "# Extract the entities from the doc object and store in the entities_list\n",
    "for ent in doc.ents:\n",
    "    entity_dict = {'text': ent.text, 'label': ent.label_}\n",
    "    entities_list.append(entity_dict)\n",
    "\n",
    "# Print the entities_list\n",
    "print(entities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_to_verb(tok):\n",
    "    verb_phrase = []\n",
    "    # First, iterate through all the ancestors of the token\n",
    "    for i in tok.ancestors:\n",
    "        # When you get to a verb (using a POS tag)...\n",
    "        if i.pos_ == \"VERB\":\n",
    "            # ...add the verb to the verb phrase list\n",
    "            verb_phrase.append(i)\n",
    "            # Then, also add the direct object(s) of the verb, as long as the original token\n",
    "            # is in the same subtree as the direct object\n",
    "            verb_phrase.extend([j for j in i.children if j.dep_ == \"dobj\" and tok in i.subtree])\n",
    "            break # as we want to find first verb only that will give us info about actions of the entity\n",
    "    # Expand out the verb phrase to get modifiers (\"amod\") of the direct object\n",
    "    for i in verb_phrase:\n",
    "        for j in i.children:\n",
    "            if j.dep_ == \"amod\":\n",
    "                verb_phrase.append(j)\n",
    "\n",
    "    # Sort the tokens by their position in the original sentence\n",
    "    new_list = sorted(verb_phrase, key=lambda x: x.i)\n",
    "    # Join them together with the correct whitespace and return\n",
    "    return ''.join([i.text_with_ws for i in new_list]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd203b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the relationships\n",
    "relationships_list = []\n",
    "\n",
    "# Loop through the entities and find relationships for each entity\n",
    "for entity in entities_list:\n",
    "    # Find the corresponding token object for the current entity\n",
    "    entity_text = entity['text']\n",
    "    entity_token = None\n",
    "    for token in doc:\n",
    "        if token.text == entity_text:\n",
    "            entity_token = token\n",
    "            break\n",
    "\n",
    "    # If the token corresponding to the entity is found, find relationships using loc_to_verb\n",
    "    if entity_token:\n",
    "        relationship = person_to_verb(entity_token)\n",
    "        # Append the relationship to the relationships_list\n",
    "        relationships_list.append({'entity': entity_text, 'relationship': relationship})\n",
    "\n",
    "# Print the relationships\n",
    "for relationship in relationships_list:\n",
    "    print(relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Last week, Akshat Engineering Services announced the launch of its new product, AkshatGPE. The phone comes with advanced features and cutting-edge technology. The launch event took place in San Francisco and was attended by tech enthusiasts from around the world. company's CEO, Sundar Pichai, delivered a keynote address, highlighting the phone's capabilities. The AkshatGPE is expected to be a game-changer in the smartphone market.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d884e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c96653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
