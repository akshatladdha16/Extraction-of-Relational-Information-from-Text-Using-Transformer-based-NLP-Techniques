{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5589ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cec4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14abeb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.31.0\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: C:\\Users\\AKSHAT RAI LADDHA\\anaconda3\\Lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1158f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f90fa9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c63f6d36bcb410c921f10b8c6e0ece5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHAT RAI LADDHA\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\AKSHAT RAI LADDHA\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147b9cec65ba406f9c787570a45a0198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7ff69c54ba419ab4b3507a591e09ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7e4cd4ce704465a438408b20da37f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[ C L S ]', '[ P A D ]'), ('J o h n', '[ u n u s e d 1 ]'), ('w o r k s', '[ u n u s e d 1 ]'), ('a t', '[ P A D ]'), ('M i c r o s o f t', '[ P A D ]'), ('C o r p', '[ u n u s e d 1 ]'), ('a s', '[ u n u s e d 1 ]'), ('a', '[ u n u s e d 1 ]'), ('s o f t w a r e', '[ P A D ]'), ('e n g i n e e r', '[ P A D ]'), ('i n', '[ u n u s e d 1 ]'), ('N e w', '[ u n u s e d 1 ]'), ('Y o r k', '[ u n u s e d 1 ]'), ('C i t y', '[ u n u s e d 1 ]'), ('.', '[ u n u s e d 1 ]'), ('[ S E P ]', '[ u n u s e d 1 ]')]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Sample text for NER\n",
    "text = \"John works at Microsoft Corp as a software engineer in New York City.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "\n",
    "# Get the predicted label ids\n",
    "predicted_label_ids = torch.argmax(outputs.logits, dim=2).squeeze()\n",
    "\n",
    "# Convert label ids back to entity labels\n",
    "labels = [tokenizer.decode(label_id) for label_id in predicted_label_ids]\n",
    "\n",
    "# Post-process to extract entities\n",
    "entities = []\n",
    "current_entity = \"\"\n",
    "for token, label in zip(tokens['input_ids'][0], labels):\n",
    "    token_str = tokenizer.decode(token)\n",
    "    if \"##\" in token_str:  # Handling subwords\n",
    "        current_entity += token_str.replace(\"##\", \"\")\n",
    "    else:\n",
    "        if current_entity:\n",
    "            entities.append((current_entity, label))\n",
    "            current_entity = \"\"\n",
    "        if label != 'O':  # 'O' represents no entity\n",
    "            entities.append((token_str, label))\n",
    "\n",
    "# Print the extracted entities\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed6fa5",
   "metadata": {},
   "source": [
    "### Model 1 :BERT NER model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47a3153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: A | Type: I-PER\n",
      "Entity: ##ks | Type: I-PER\n",
      "Entity: ##hat | Type: I-PER\n",
      "Entity: Care | Type: I-ORG\n",
      "Entity: ##lon | Type: I-ORG\n",
      "Entity: Global | Type: I-ORG\n",
      "Entity: Solutions | Type: I-ORG\n",
      "Entity: Bangalore | Type: I-LOC\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\") #using ner trained model by hugging face to extract entites \n",
    "\n",
    "# Example text\n",
    "text = \"Myself Akshat, worked as ML intern in Carelon Global Solutions from May to June in Bangalore\"\n",
    "\n",
    "# Perform Named Entity Recognition on the text\n",
    "entities = ner_pipeline(text)\n",
    "\n",
    "# Print the recognized entities\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']} | Type: {entity['entity']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4b859",
   "metadata": {},
   "source": [
    "Extracted entities with particular information using NER model from hugging face. Generation of subwords from words such as Akshat to A, ##ks, ##hat this is because the model's tokenizer is based on WordPiece tokenization, where words are split into subword units to handle out-of-vocabulary (OOV) words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04177b16",
   "metadata": {},
   "source": [
    "### trying out luck with other fine tuned models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a2ab5",
   "metadata": {},
   "source": [
    "### Model 2: Fine Tuned BERT model for entity extraction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12397d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a4868952db4516aac263bc3efcc84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKSHAT RAI LADDHA\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\AKSHAT RAI LADDHA\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc072dcbaa6c44afb018da85bd8224d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/431M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fedc40e348b409d9ff4bb167d0cc16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8214092c2b3048c3b796c5fd772ffebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0326595e8014b28a321cad8c7b0caca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e317796018ef460d89588eec05641038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Loading the pipeline from hub\n",
    "# Pipeline handles the preprocessing and post processing steps\n",
    "model_checkpoint = \"balamurugan1603/bert-finetuned-ner\"\n",
    "namedEntityRecogniser = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f2f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Myself Akshat Rai Laddha, working as ML intern at Carelon global Solution in Bangalore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e2182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output = namedEntityRecogniser([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bcc9f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'PER', 'score': 0.99700034, 'word': 'Akshat Rai Laddha', 'start': 7, 'end': 24}, {'entity_group': 'ORG', 'score': 0.90261436, 'word': 'ML', 'start': 37, 'end': 39}, {'entity_group': 'ORG', 'score': 0.8897029, 'word': 'Carelon global Solution', 'start': 50, 'end': 73}, {'entity_group': 'LOC', 'score': 0.9953557, 'word': 'Bangalore', 'start': 77, 'end': 86}]]\n"
     ]
    }
   ],
   "source": [
    "print(sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40965c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "327f7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(pipeline_output, texts):\n",
    "    \n",
    "    \"\"\" Visualizes text and their Named entities.\n",
    "    \n",
    "    Args:\n",
    "        pipeline_output (list): Output of the pipeline.\n",
    "        texts (list): List containing original text.\n",
    "    \n",
    "    Returns:\n",
    "        Nothing\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(sample_output)):\n",
    "        entities = []\n",
    "        for ents in sample_output[i]:\n",
    "            entities.append({\"end\": ents[\"end\"], \"label\": ents[\"entity_group\"], \"start\": ents[\"start\"]})\n",
    "        displacy.render({\n",
    "            \"ents\": entities,\n",
    "            \"text\": texts[i]\n",
    "        }, style=\"ent\", manual=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d53acfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Myself \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Akshat Rai Laddha\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", working as \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ML\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " intern at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Carelon global Solution\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bangalore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(sample_output, [text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5670694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
